# Prompt Writing Guide

**Audience:** Developers, Product Owners, Prompt Engineers  
**Last Updated:** October 29, 2025  
**Status:** Production Standard

---

## üéØ Core Philosophy

**Write prompts as if you're onboarding a smart new joiner fresh from school.**

They're intelligent and capable, but they need clear, unambiguous instructions.

---

## üìã The Template Structure

Use this proven structure from our unified extraction prompt (`backend/app/api/services/prompts/unified_extraction.md`):

```markdown
[ROLE]
Clear job description - who they are and what they do

[TASK 1: Primary Task Name]
What they need to accomplish

CONCEPTS & PRINCIPLES:
Core concepts they need to understand

CHAIN-OF-THOUGHT ALGORITHM:
Step-by-step decision process (Q1, Q2, Q3...)

EXAMPLES:
Concrete examples showing the reasoning

RULES SUMMARY:
Quick reference of critical rules

[TASK 2: Secondary Task Name]
...repeat structure...

[OUTPUT SCHEMA]
Exact JSON/format expected
```

---

## 1. [ROLE] - Job Description

**Goal:** Define who the LLM is and what their overall purpose is.

**Template:**
```markdown
[ROLE]
You are a [JOB_TITLE] for [SYSTEM/PURPOSE].
[Brief description of responsibilities]
```

**Example:**
```markdown
[ROLE]
You are a comprehensive EXTRACTION engine for a personal assistant.
Extract facts, resolve entity ambiguities, and identify conversation topics in ONE analysis.
```

**Why This Works:**
- ‚úÖ Gives the LLM a clear identity and purpose
- ‚úÖ Sets context for all subsequent instructions
- ‚úÖ Like telling a new employee their job title and department

---

## 2. [TASK X] - Break Down the Job

**Goal:** Divide the complex job into discrete, manageable tasks.

**Template:**
```markdown
[TASK 1: SPECIFIC_TASK_NAME]

Brief task description

CRITICAL CONCEPTS:
- Key concept 1
- Key concept 2

RULES:
1. Specific rule
2. Specific rule
```

**Example:**
```markdown
[TASK 1: FACT EXTRACTION]

Extract verifiable, atomic facts from the user message.

CRITICAL CONCEPT: Extract ONLY PERSISTENT facts, NOT transient actions/queries

THE KEY QUESTION: "Is this something worth remembering BEYOND this conversation moment?"

RULES:
1. Every fact MUST be complete sentence with clear subject
2. Use "User" prefix for first-person (I, me, my)
3. Named entities start with their name
```

**Why This Works:**
- ‚úÖ Clear boundaries for each task
- ‚úÖ LLM knows what to focus on in each section
- ‚úÖ Like giving a new joiner their specific responsibilities

---

## 3. CONCEPTS & PRINCIPLES - The "Why"

**Goal:** Teach underlying concepts before giving instructions.

**Template:**
```markdown
**THE KEY CONCEPT:** [Central idea]

**UNDERSTANDING THE DISTINCTION:**

‚úÖ **Category A (DO THIS):**
Things that meet criteria X:
- Example 1
- Example 2

‚ùå **Category B (AVOID THIS):**
Things that meet criteria Y:
- Example 1
- Example 2
```

**Example:**
```markdown
**CRITICAL CONCEPT: Extract ONLY PERSISTENT facts, NOT transient actions/queries**

**THE KEY QUESTION:** "Is this something worth remembering BEYOND this conversation moment?"

**PERSISTENT Facts (EXTRACT these):**

Things that are TRUE OVER TIME - would still be relevant next week/month:

‚úÖ **Identity & Attributes:**
   - "I'm allergic to peanuts", "I'm vegetarian"
   - "I work at Microsoft", "I'm a software engineer"

‚ùå **TRANSIENT Actions/Queries (SKIP these):**

Things happening RIGHT NOW in this moment - not worth remembering:

‚ùå **Immediate action requests:**
   - "I want to check my emails" ‚Üí Action RIGHT NOW
   - "Can you search the documentation?" ‚Üí Query RIGHT NOW
```

**Why This Works:**
- ‚úÖ LLM understands the reasoning, not just following rules blindly
- ‚úÖ Can generalize to novel situations
- ‚úÖ Like explaining the company's philosophy to a new joiner

---

## 4. CHAIN-OF-THOUGHT (COT) ALGORITHMS

**Goal:** Provide step-by-step decision processes that are deterministic and unambiguous.

**Template:**
```markdown
**CHAIN-OF-THOUGHT DECISION PROCESS:**

For EACH [item], ask yourself these questions IN ORDER:

**Q1: [First decision point]**
   - Indicator A
   - Indicator B
   - If YES ‚Üí [action/next step]
   - If NO ‚Üí Go to Q2

**Q2: [Second decision point]**
   - Indicator C
   - Indicator D
   - If YES ‚Üí [action/next step]
   - If NO ‚Üí Go to Q3

**Q3: [Third decision point]**
   - If YES ‚Üí [final action]
   - If NO ‚Üí [alternative action]

**THE FINAL TEST:**
"[Simple yes/no question to validate]"
- YES ‚Üí [action]
- NO ‚Üí [action]
```

**Example:**
```markdown
**CHAIN-OF-THOUGHT DECISION PROCESS:**

For EACH potential fact, ask yourself these questions IN ORDER:

**Q1: Is this an ACTION REQUEST or QUERY?**
   - "Can you X?", "Please Y", "I want to Z"
   - If YES ‚Üí Check Q2
   - If NO ‚Üí Go to Q3

**Q2: Does the action/query reveal a PERSISTENT plan or preference?**
   - "Can you book a flight to London?" ‚Üí YES, reveals travel plan ‚Üí EXTRACT the plan
   - "Can you check my emails?" ‚Üí NO, just an immediate request ‚Üí SKIP
   - If YES ‚Üí EXTRACT
   - If NO ‚Üí SKIP

**Q3: Is this describing a CURRENT MOMENT activity?**
   - Indicators: "I'm [verb]-ing", "right now", "currently"
   - If YES ‚Üí SKIP (not persistent)
   - If NO ‚Üí Go to Q4

**Q4: Is this a PERSISTENT truth about the user?**
   - Identity, relationships, preferences, allergies
   - If YES ‚Üí EXTRACT
   - If NO ‚Üí SKIP

**THE FINAL TEST:**
"Would the user want me to remember this NEXT WEEK?"
- YES ‚Üí EXTRACT
- NO ‚Üí SKIP
```

**Why This Works:**
- ‚úÖ Eliminates ambiguity - clear decision tree
- ‚úÖ LLM follows the same logic every time (consistency)
- ‚úÖ Debuggable - you can trace where it went wrong
- ‚úÖ Like giving a new joiner a flowchart for common decisions

---

## 5. EXAMPLES - Show, Don't Just Tell

**Goal:** Demonstrate the COT algorithm in action with diverse scenarios.

**Template:**
```markdown
**EXAMPLES:**

Example 1: [Scenario type] ([Expected outcome])
Input: "[example input]"
REASONING:
Q1: [answer] ‚Üí [next step]
Q2: [answer] ‚Üí [decision]
OUTPUT: [what to extract/do]

Example 2: [Different scenario] ([Different outcome])
Input: "[example input]"
REASONING:
Q1: [answer] ‚Üí [next step]
Q3: [answer] ‚Üí [decision]
OUTPUT: [what to extract/do]
```

**Example:**
```markdown
Example 1 - PERSISTENT (Extract):
Message: "I'm allergic to peanuts and I love Italian restaurants"
‚úÖ Extract: "User is allergic to peanuts" (Allergy, CRITICAL)
‚úÖ Extract: "User loves Italian restaurants" (Preference, NORMAL)

Example 2 - TRANSIENT (Skip):
Message: "Can you check my emails from today?"
‚ùå Extract: NONE (immediate action request, not worth remembering)

Example 3 - ACTION REQUEST revealing PLAN (Extract the plan):
Message: "Can you book a flight to London for next week?"
REASONING:
Q1: Action request? YES ‚Üí Check Q2
Q2: Reveals persistent plan? YES - user IS planning to travel to London
‚úÖ Extract: "User is planning to travel to London next week" (Travel)
```

**Why This Works:**
- ‚úÖ Shows the COT algorithm in practice
- ‚úÖ Covers edge cases and common scenarios
- ‚úÖ LLM learns from examples (few-shot learning)
- ‚úÖ Like showing a new joiner how previous employees handled similar cases

---

## 6. RULES SUMMARY - Quick Reference

**Goal:** Provide a condensed checklist for quick validation.

**Template:**
```markdown
**KEY RULES SUMMARY:**

1. ‚úÖ [Rule for what TO do]
2. ‚úÖ [Another rule for what TO do]
3. ‚ùå [Rule for what NOT to do]
4. ‚ùå [Another rule for what NOT to do]
5. **Default if unclear ‚Üí [safe fallback]**
```

**Example:**
```markdown
**KEY RULES SUMMARY:**

1. ‚úÖ Possessive from user (my/our) ‚Üí PERSONAL
2. ‚úÖ Possessive chain (my X's Y) ‚Üí PERSONAL (indirect)
3. ‚úÖ Interaction with user ‚Üí PERSONAL
4. ‚ùå Knowledge query about them ‚Üí REFERENCE
5. ‚ùå Public figure with no personal context ‚Üí REFERENCE
6. **Default if unclear ‚Üí REFERENCE** (safer)
```

**Why This Works:**
- ‚úÖ Easy to scan and validate
- ‚úÖ Reinforces most important rules
- ‚úÖ Like a one-page cheat sheet for a new joiner

---

## 7. [OUTPUT SCHEMA] - Clear Expectations

**Goal:** Define exactly what format the output should be.

**Template:**
```markdown
[OUTPUT SCHEMA]

Return ONLY this JSON structure (no markdown, no extra text):

{
  "field1": "value type and constraints",
  "field2": ["array", "of", "valid", "values"],
  "field3": {
    "nested": "object structure"
  }
}

CRITICAL FIELD MAPPINGS:

**field1** (purpose and valid values):
  - "value1" ‚Üí meaning
  - "value2" ‚Üí meaning
  
**CRITICAL RULES:**
- If X ‚Üí System will do Y
- If Z ‚Üí System will do W
```

**Example:**
```markdown
[OUTPUT SCHEMA]

Return ONLY this JSON structure (no markdown, no extra text):

{
  "facts": [
    {
      "type": "FactType enum value",
      "text": "Complete fact sentence",
      "confidence": 0.95
    }
  ]
}

CRITICAL FIELD MAPPINGS:

**type** (ONLY use these FactType enum values):
  - "Allergy" ‚Üí allergies, medical restrictions
  - "Preference" ‚Üí likes, dislikes, habits
  - "Relationship" ‚Üí family, friends, colleagues
  
CRITICAL RULES:
- NEVER use: "Promotion", "Career", "Job" (not valid enum values)
- Every fact MUST be a complete sentence
```

**Why This Works:**
- ‚úÖ No ambiguity about output format
- ‚úÖ Prevents common errors (invalid enum values, wrong structure)
- ‚úÖ Like giving a new joiner the exact template to fill out

---

## Complete Prompt Template

Here's the full structure to follow:

```markdown
[ROLE]
You are a [JOB_TITLE] for [PURPOSE].
[1-2 sentence job description]

[TASK 1: PRIMARY_TASK]

[What to accomplish]

**CRITICAL CONCEPT:** [Core principle]

**THE KEY QUESTION:** "[Guiding question]"

**UNDERSTANDING THE DISTINCTION:**

‚úÖ **Category A (DO THIS):**
- Example
- Example

‚ùå **Category B (AVOID THIS):**
- Example
- Example

---

**CHAIN-OF-THOUGHT DECISION PROCESS:**

For EACH [item], ask yourself IN ORDER:

**Q1: [Decision point]**
   - If YES ‚Üí [action]
   - If NO ‚Üí Q2

**Q2: [Decision point]**
   - If YES ‚Üí [action]
   - If NO ‚Üí Q3

**THE FINAL TEST:**
"[Validation question]"
- YES ‚Üí [action]
- NO ‚Üí [action]

---

**EXAMPLES:**

Example 1: [Scenario] ([Outcome])
Message: "[input]"
REASONING:
Q1: [step]
Q2: [step]
OUTPUT: [result]

Example 2: [Different scenario] ([Different outcome])
[... same structure ...]

---

**KEY RULES SUMMARY:**

1. ‚úÖ [DO this]
2. ‚úÖ [DO this]
3. ‚ùå [DON'T do this]
4. **Default ‚Üí [safe fallback]**

---

[TASK 2: SECONDARY_TASK]

[Repeat structure above]

---

[OUTPUT SCHEMA]

Return ONLY this JSON:

{
  "field": "type and constraints"
}

CRITICAL FIELD MAPPINGS:
[Explain valid values and mappings]
```

---

## ‚úÖ Prompt Writing Checklist

Before finalizing your prompt, check:

### **Structure:**
- ‚úÖ **[ROLE]** defined?
- ‚úÖ Tasks broken down clearly?
- ‚úÖ Each task has CONCEPTS section?
- ‚úÖ Each task has COT algorithm?
- ‚úÖ Each task has EXAMPLES?
- ‚úÖ Rules summary included?
- ‚úÖ Output schema defined?

### **Clarity:**
- ‚úÖ Can a smart high school graduate follow this?
- ‚úÖ Are decision trees unambiguous (clear if/then)?
- ‚úÖ Are examples diverse (cover edge cases)?
- ‚úÖ Are concepts explained with examples?

### **Completeness:**
- ‚úÖ Edge cases covered in examples?
- ‚úÖ Common errors explicitly warned against?
- ‚úÖ Default/fallback behavior specified?
- ‚úÖ Valid enum values listed exhaustively?

### **Quality:**
- ‚úÖ Uses ‚úÖ and ‚ùå for clarity?
- ‚úÖ Bold for **critical concepts**?
- ‚úÖ Numbered questions (Q1, Q2, Q3)?
- ‚úÖ "THE KEY QUESTION" highlighted?

---

## üìö Reference Examples

### **Unified Extraction Prompt (GOLD STANDARD)**
**Location:** `backend/app/api/services/prompts/unified_extraction.md`

Perfect example of:
- Role ‚Üí Tasks ‚Üí Concepts ‚Üí COT ‚Üí Examples ‚Üí Rules ‚Üí Schema
- Used for fact extraction, entity disambiguation, topic extraction, preference detection

### **UI Node Prompts**
**Location:** `backend/app/api/services/agents/global_supervisor/nodes/ui_node_helpers/`

- Uses `professional_prompt_builder.py`
- Has `prompts/core.md`, `prompts/simple.md`, `prompts/complex.md`, etc.

### **Intent Classification Prompt**
**Location:** `backend/app/api/services/agents/global_supervisor/nodes/intent_classification_helpers/`

- Uses `prompt_builder.py`
- Has `prompts/intent_classification.md`

---

## üìñ Related Documentation

- **Prompt Asset Management Pattern:** `docs/Documentation/prompt_asset_management_pattern.md`
- **AGENTS.md:** Project-wide architecture guide
- **PROMPT_EDITING_GUIDE.md:** How to edit existing prompts

---

**Questions?** Refer to the gold standard example or ask the development team! üöÄ

